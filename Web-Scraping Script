from urllib.request import urlopen as uReq
from bs4 import BeautifulSoup as soup

my_url = 'https://www.amazon.com/s?k=exfoliant&crid=159BF7G4O5QQ8&sprefix=exfoliant%2Caps%2C147&ref=nb_sb_noss_1'

# opening up the connection, grabbing the page
uClient = uReq(my_url)
page_html = uClient.read()
uClient.close()

# html parsing
page_soup = soup(page_html, "html.parser")

# grabs each product
containers = page_soup.findAll("div", {"class":"item container"})

# use jsbeautiful on container[idx]

# opening/writing csv
filename = "products.csv"
f = open(filename, "w")

    # headers
    headers = "brand, product_name, shipping\n"

    f.write(headers)

# scraping loop
for container in containers:
        brand = container.div.div.a.img["title"]

        title_container = container.findAll("a", {"class":"item-title"})
        product_name = title_container[0].text

        shipping_container = container.findAll("li", {"class":"price-ship"})
        shipping = shipping_container[0].text.strip()

        print("brand: " + brand)
        print("product_name: " + product_name)
        print("shipping: " + shipping) 

        f.write(brand + "," + product_name.replace(",", "|") + "," + shipping + "/n")

f.close()